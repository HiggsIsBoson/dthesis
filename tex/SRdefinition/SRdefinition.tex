\chapter{Event Selection} \label{sec::SRdefinition}
The goal of this chapter is to define the signal regions in which the compatibility between data and background-only or SUSY signal hypotheses are tested. 
Different level of event selection will be discussed from the pre-selection including trigger selection, event cleaning selection, design of the signal region binning, and the optimization of background rejection cuts.
Finally the decided signal regions are validated via inspecting the expected limits,
which is shown in Sec. \ref{sec::SRdefinition::expLimit}.\\


\section{Trigger Selection} \label{sec::SRdefinition::trigger}
The missing $\ET$ trigger (MET trigger) is primarily used throughout the analysis.
Since the lowest unprescaled trigger kept evolved according to the increased instantaneous luminosity during the data taking, a number of different triggers are used in combination.
The list of relevant triggers are shown in Table \ref{tab::SRdefinition::METtriggers},

\tabsmall{ccc|cc}{

\hline
Period      &  Peak lumi. [cm$^{-2}$ s$^{-1}$]  &  Int. lumi. [fb$^{-1}$]  &   L1 (HLT) item       &  L1/HLT/Off-line thres. [GeV]  \\
\hline
2015        &  0.50 $\times 10^{34}$                                     &  3.19                         &   L1XE50 (xe70\_mht)   &  50 / 70 / 200  \\
2016 A-D1   &  0.99 $\times 10^{34}$                                     &  6.12                         &   L1XE50 (xe90\_mht)   &  50 / 90 / 200   \\
2016 D1-F1  &  1.03 $\times 10^{34}$                                      &  6.55                        &   L1XE50 (xe100\_mht)  &  50 / 100 / 200  \\
2016 F2-    &  1.21 $\times 10^{34}$                                      &  20.2                        &   L1XE50 (xe110\_mht)  &  50 / 110 /  200   \\
\hline
}
{Summary of MET triggers used in the analysis along the peak luminosity evolution. Corresponding on-line and off-line threshold are shown in the rightest column.}
{tab::SRdefinition::METtriggers}

% needed description 
% off-line MET -> cluster based
% on/off-line definition
%Taking the advantage that most of the targeted signal models result in large missing ET (MET) due to the presence of LSPs, the lowest unprescaled MET trigger (HLT\_xe110\_mth\_XE50) is used for triggering events throughout the analysis. 

The efficiency curve as function of off-line $\met$ is shown in Figure \ref{fig::SRdefinition::METtrig}, taking HLT\_xe100\_mht as an example.
Thanks to the fact that $\met$ is calculated from the global information of an event, rather than the local feature around a single particle, the plateau efficiency achieves almost 100 $\%$. 
This is a significant advantage over the use of particle-based trigger (e.g. single-lepton trigger) where efficiency is typically $70\% \sim 90\%$. 
Generally the downside of MET trigger is on the other hand its slow turn-on in terms of the off-line MET that needs nearly $200 \gev$ to assure the plateau efficiency despite much lower trigger threshold ($<110$ GeV). This is due to the deteriorated resolution of on-line MET calculated only with calorimeter deposit, with respect to the off-line one which in addition takes muons and soft tracks into account. 
The signal acceptance by the MET trigger requirement is $>95\%$ only except when the masses of gluino and LSP are compressed. 
This is however not problematic eventually, since it turns that large-$\met$ is anyway necessary for such signal to be discriminated against the background. \\

%The turn-on also has dependency on event topology and kinematics due to varying MET resolution in particular sensitive to magnitude of jet activity, however this does not affect the plateau efficiency. Figure \ref{fig::SRdefinition::metTrigEff} shows turn-ons with different jet multiplicity. \\

The single-lepton trigger (SLT) is also used for supplemental purpose, including the efficiency measurement of MET trigger and data-driven background estimation. 
The trigger turn-on is about $28\gev$ ($26\gev$) for single-electron (muon) in its transverse momentum and $30\gev$ ($28\gev$) is required as off-line threshold. \\

\fig[160]{SRdefinition/trigEff/metTrig_huajie.pdf}
{Measured and simulated efficiency for HLT\_xe100\_mht performing the tag-and-probe technique on $\wjets$ events. The efficiencies in events with (a) exactly one muon, and (b) exactly one electron are shown (by Huajie Cheng).}
{fig::SRdefinition::METtrig}


% -------------- MET trigger eff.  
%\begin{figure}
%  \begin{center}
%    \includegraphics[width=100mm]{figures/SRdefinition/trigEff/metTrigEff_lepTrigTag.eps}
%    \captionof{figure}{Efficiency curve of MET trigger measured with data by tagging a lepton with $p_{T}(\ell_{1})>35\gev$ firing the single-lepton trigger.}
%    \label{fig::SRdefinition::metTrigEff}
%  \end{center}
%\end{figure}




\section{Event Cleaning and the Pre-selection} \label{sec::SRdefinition::eventCleaning}
Event cleaning is then applied to get rid of funky data events such as ones in bad detector condition or with unqualified objects including cosmic muons and the beam-induced background. 
Since those events could result in extraordinary observables, for instance extremely high jet $\pt$ or $\met$, 
the contamination in signal regions can be critical even with a few events for the analyses that probes the high-end of kinematics where only a few background events in are expected.
% where therefore even a single event of the accidental contamination makes huge impact on the final result. 
The list of cleaning cuts and the efficiencies are shown in Table \ref{tab::SRdefinition::EvtCleaning}. 

\tab{ c | c | c }{
  \hline
                       Cut              &  Efficiency (Data) $[\%]$   &  Efficiency (MC, $\ttbar$) $[\%]$  \\
  \hline
  \hline
  Veto bad lumi-blocks                  & 95.12                            &  100.0        \\
  Veto bad DAQ events                   & 99.81                            &  100.0        \\
  Veto events with no reconstructed primary vertex    & 100.0                            &  100.0        \\
  Veto events with cosmic muons         & 95.83                            &  98.52        \\
  Veto events with badly measured jets  & 99.49                            &  99.65        \\
  Veto events with badly measured muons & 99.99                            &  98.56        \\              
  \hline
}
{List of event cleaning requirements. Data and MC shows different efficiencies up-to the top four since MC does not emulates bad data quality and cosmic muons in it.}
{tab::SRdefinition::EvtCleaning}

Firstly, lumi-blocks with more than $10\%$ of any of the sub-detector in the inappropreate status are removed, 
Events affected by noise bursts in LAr and SCT, corrupted data transmission in LAr and the Tile calorimeter are then vetoed subsequently. 
%Event cleaning for badly measured objects applied rather conservatively giving that they could easily generate large fake MET that makes itself highly signal-like.
Cosmic muon are vetoed by requiring the muon track passing reasonably close-by the primary vertex i.e.
$|z_0| < 1\, \mathrm{mm}, \,\,\, d_0<0.2\, \mathrm{mm}$. 
The beam induced backgrounds are events with muons that are generated by the secondary cascades of protons traveling upstream of the interaction point. The energy depositions created by these muons can be reconstructed as jets with energy as high as the beam energy therefore becomes highly signal-like. To reject the fake jets, event with jets flagged as ``BadLoose'' described in \cite{BadJetCriteriaATLAS2015} are vetoed. 
High energy muons with poor momentum measurement quality are also a source of fake high MET ranging upto a few TeV.
Those are defined by $\sigma(q/p) / (q/p) > 0.2$ where $q$ is muon charge, $p$ the momentum and $\sigma(q/p)$ is the fitting error.
The entire events will be vetoed if containing at least one such bad muon. 
Figure \ref{fig::SRdefinition::badMuonVeto} demonstrate the performance of the bad muon veto. 
While the bad muon events typically peak at $\Delta \phi (l,\met) \sim \pi$ since the fake MET aligns with the muon, 
it is not the case anymore after the veto. \\


\begin{figure}[h]
  \centering
    \subfig{0.488}{figures/SRdefinition/badMuons/met_met0TeV.pdf}{}
    \subfig{0.488}{figures/SRdefinition/badMuons/dPhi_met_lep_met1TeV.pdf}{}
    \caption{(a) $\met$ distribution after requiring exactly one signal muon and MET trigger, and (b) $\Delta \phi (l,\met)$ distribution with $\met>1\tev$ being applied. The pink histogram corresponds to events dropped by the bad muon veto. It is shown that the 1-muon high MET phase space generally suffers from severe contamination by bad muon events up to about 20$\%$ (90$\%$) with  $\met>1(2)\tev$.}
    \label{fig::SRdefinition::badMuonVeto}
\end{figure}

The pre-selection is the common selection for all the signal regions in the analysis, which is defined as Table \ref{tab::SRdefinition::Preselection}. 
Figure \ref{fig::SRdefinition::validationMT_presel} is a validation plot showing transverse mass ($\mt$; invariant mass of lepton $\pt$ and MET) of the data and MC, 
after the pre-selection being applied. \\

\tab{ c }{
  \hline
  Event cleaning \\
  Pass the MET trigger and $\met>250\gev$ \\
  Exactly one signal electron (muon) with $\pt>7(6)\gev$. \\
  At least two jets with $\pt>30\gev$. \\
  \hline
}
{List of requirements for the 1-lepton pre-selection.}
{tab::SRdefinition::Preselection}


\fig[110]{SRdefinition/Preselection/mt_1LPrecut_fineBins.pdf}
{Transverse mass ($\mt$; invariant mass of lepton $\pt$ and MET) distribution after the pre-selection (Table \ref{tab::SRdefinition::Preselection}). The Jacobian peak and the cut-off structure at $\mt\sim m_W$ are clearly seen.}
{fig::SRdefinition::validationMT_presel}
%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Signal Region Definition}
\subsection{Binning Strategy}
To inclusively address to all the 45 decay chains and all possible mass spectra, a set of tailored multi-bin signal regions (SRs) are employed, based on the following binning stragey:
\begin{itemize}
\item split SRs in terms of $b$-jet multiplicity (``$b$-categories'') to cover different gluino decays, 
\item split SRs in terms of number of jets and lepton-$\pt$ (``towers'') to cover various patterns of the mass spectra. 
\item split SRs in terms of $\meffInc (\meffDef)$ (``$\meffInc$-bins'') to cover different absolute mass splitting between gluino and LSP. 
\end{itemize}
The SRs are in principle designed to be exclusive for each other, aiming at an easy combination afterward so that no signals are lost due to the binning. 

\paragraph{\underline{\textbf{$b$-categories}}} \mbox{} \\
The ``categories'' are defined based on $b$-multiplicity; $b$-vetoed (BV); $b$-tagged (BT); and 3B, as shown in Table \ref{tab::SRdefinition::categoriesDef}. 
The customers of these categories are respectively the models in Table \ref{tab::Introduction::modelsBV}, \ref{tab::Introduction::modelsBT} and \ref{tab::Introduction::models3B} in Sec. \ref{sec::Introduction::targetModels}, which are referred as ``BV'', ``BT'' and ``3B'' benchmark models from now on. 
The $b$-jet multiplicity for the reference signal models and the background at the pre-selection level is shown in Figure \ref{fig::SRdefinition::nB}.
Note that despite a fraction of signal events falling into other categories than the benchmarked one, they will not be wasted thanks to the combined fit performed in deriving the final result.
As the $S/N$ ratio and the background kinematics in BV/BT are found to be more or less similar, further kinematical selections in those categories are set to identical for simplicity. 
On the other hand, different selection strategy is adopted for the 3B categories since the background level is significantly lower and also the composition is very different. \\

%%%
\tab{ c | c | c }{
\hline
Category    & $b$-jet multiplicity   & Main background \\ 
\hline
\hline
$B$-vetoed (BV) & 0        & $\wjets$ \\
$B$-tagged (BT) & 1-2      & $\ttbar$ \\
3B            & $\geq 3$ & $\ttbar$, $\ttbar+cc/bb$ \\
\hline
}
{The definition of the ``$b$-categories'' and the main backgrounds.}
{tab::SRdefinition::categoriesDef}
%%%
\fig[110]{SRdefinition/discVar/nBJet30__Precut.pdf}
{$B$-jet multiplicity for the standard model backgrounds (colored stack) and the reference signals after the 1-lepton pre-selection (dashed lines); \textbf{QQC1QQC1} for the BV; \textbf{QQC1BTC1} for the BT; and \textbf{TTN1TTN1} for the 3B category.}
{fig::SRdefinition::nB}
%%%

\clearpage
\paragraph{\underline{\textbf{Towers}}} \mbox{} \\
The BV/BT categories are further divided into 4 ``towers'', 
to cope with the four representative configurations of the mass spectra in case of the 1-step decays. The four configurations and resultant observables are schematized in Figure \ref{fig::SRdefinition::binning_BTBV} with the reference model \textbf{QQC1QQC1} being taken as an example, which is namely:
%
\begin{description}
\item \textbf{Intermediate EW gaugino is halfway between gluino and LSP ($x \sim 1/2$).} 
\footnote{ $x$ is defined by Eq. (\ref{eq::def_x})}
\\
This is the most standard configuration where particles from both gluino and the intermediate EW gaugino decays are hard enough to pass the criteria of hard lepton ($>35\gev$) and jets ($\pt>30\gev$). As the signals targeted by the BV/BT categories typically result in $4-10$ jets at the tree-level, a tower \textbf{6J} with $\nJetNoGev \geq 6$ is defined. 

\item \textbf{Gluino and EW gauginos are all compressed.} \\ 
From either trigger and background separation point of view, hard ISRs are indispensable for probing this type of signatures so that the $\tilde{g}\tilde{g}$ system gets kicked and resulting in large MET. On the other hand, as the kicked gluinos are typically enough heavy to be non-relativistic, the transverse momentum of the boosted $\tilde{g}\tilde{g}$ system is almost solely converted into MET. As a result the particles from gluino decays stay soft. The \textbf{2J} tower consisting of a soft lepton, at least two hard jets and large MET is defined for targeting the signature.

\item \textbf{The intermediate EW gaugino and gluino or LSP are compressed ($x \sim 0,1$)}.  \\
There are also extreme cases where the intermediate EW gaugino mass is degenerate toward either of gluino or LSP and decoupled from the other. Two signal region towers: \textbf{High-x} and \textbf{Low-x} are employed to cover the scenarios. Note that the DM-oriented scenario is targeted by tower \textbf{Low-x}.
\end{description}
%
\noindent Direct gluino decay models are covered by the towers \textbf{2J} and \textbf{6J} i.e. \textbf{2J} deals with the scenario of compressed mass spectra between gluino and LSP while \textbf{6J} takes care of the other cases. \\

In contrast to the BV/BT category, the 3B does not undergo the additional classification in towers since the targeted signal models usually involve top quarks that can result in hard jets, hard leptons and MET. 
Therefore the kinematics does not dramatically vary between the mass configurations unless the top-quarks are on-shell.
The only exception is when gluino and the intermediate EW gaugino get compressed, and the top-quarks turn to off-shell ending up in only soft particles.
However, such events are then covered by the BV and BT towers instead, thanks to the dropped $\geq 3$ $b$-jet acceptance according to the decreasing $b$-quarks' $\pt$. \\ 

To summarize, 5 towers (\textbf{2J}/\textbf{6J}/\textbf{Low-x}/\textbf{High-x}/\textbf{3B}) are defined in total out of 3 categories (BV/BT/3B) as shown in Table \ref{tab::SRdefinition::towersDef}. 
%The sensitivity converage by each signal region tower on the mass grid of the signal models are shown in Figure \ref{fig::SRdefinition::towerCoverage}.

%%%%%%%%%%
\fig[160]{SRdefinition/EventSelection/binning_BTBV.eps}{The four signal region towers for the BT/BV categories, and their targeted mass configuration.}{fig::SRdefinition::binning_BTBV}

%%%
%\tab{ c | c | c | c | c }{
\tab{ c | c | c | c }{
\hline
%Category & Tower    & Electron (muon) $\pt$ [GeV]  &  $\nJet$ & Jet $\pt$ [GeV]\\ 
$b$-category & Tower    & Electron (muon) $\pt$ [GeV]  &  $\nJet$  \\ 
\hline
\hline
      & 2J     & $\in [7(6), 35] $  & $\geq 2$ \\ \cline{2-4}
BV/BT & 6J     & $>35$              & $\geq 6$ \\ \cline{2-4}
      & $\Lowx$  & $\in [7(6), 35] $  & $\geq 4$ \\ \cline{2-4}
      & $\Highx$ & $>35$              & $\geq 4$ \\
\hline
3B    & \textbf{3B}     & $>15$              & $\geq 7$ \\
\hline
}
{List of defined towers in each $b$-category and the kinematical selection required. \textbf{2J} and \textbf{6J} (or \textbf{Low-x} and \textbf{High-x}) are orthogonal to each other. \textbf{3B} are orthogonal to all the other towers.}
{tab::SRdefinition::towersDef}
%%%


\clearpage
\paragraph{\underline{\textbf{$\meffInc$-bins}}} \mbox{} \\
Finally, the towers further experience the binning in terms of $\meffInc$ 
defined by the scalar sum of the transverse momenta of leptons and jets, and $\met$,
in order to accommodate different scale of absolute mass splitting $\dmg$. 
The \textbf{2J}/\textbf{6J} and \textbf{3B} tower are segmented into 3 and 2 bins respectively, while \bLowx and \bHighx stay a single bin as their low-$\meffInc$-bins have too much overlap with \textbf{2J} and \textbf{6J}. The bin widths of $\meffInc$ are chosen to be $400\gev-500\gev$ based on the width of $\meffInc$ distribution that targeted signals typical have. The \textbf{3B} tower enjoys an exceptionally wider bin width with $750\gev$, compromising with limited of statistics in corresponding control regions. \\
%The lower bound of the last $\meffInc$ 

To conclude, the signal regions end up in 5 tower-structured bins as schematized as Figure \ref{fig::SRdefinition::SRbinning}, where $3 \times 2$ bins in $\meffInc \times \mathrm{(BV/BT)}$ reside in the tower \textbf{2J} and \textbf{6J}; $1 \times 2$ bins in \textbf{Low-x} and \textbf{High-x}; and 2 $\meffInc$-bins in \textbf{3B}. SRs bins in the towers are orthogonal each other except that \textbf{2J} (\textbf{6J}) and \textbf{Low-x} (\textbf{High-x}) are partially overlapped. 
%%% In providing the result, we perform the fit for both two combined towers, and quote one giving the best sensitivity
%
%The left plots of of Figure \ref{fig::SRdefinition::expLimitQQC1QQC1}-\ref{fig::SRdefinition::expLimitTTN1TTN1} present the mass spaces that each signal tower is supposed to address the sensitivity in the mass grids of benchmark models (footnote: in fact these are the expected exclusion limit by the finalized the signal regions after all the optimization, but also good enough to give some idea how each signal region interplay and complement the sensitivity each other).
Figure \ref{fig::SRdefinition::towerCoverage1}-\ref{fig::SRdefinition::towerCoverage2} schematize the mass regions in the signal grids that each tower or bin is supposed to address the sensitivity.

%%%%%%%%%%%
\fig[110]{SRdefinition/EventSelection/SRbinning.pdf}
{Tower structure and the $\meffInc$-binning of the signal regions.}
{fig::SRdefinition::SRbinning}
%%%%%%%%%%%

\begin{figure}[h]
  \centering
    \subfig{0.7}{figures/SRdefinition/EventSelection/TowerCoverage_BVBT_x12.pdf}{}
    \subfig{0.7}{figures/SRdefinition/EventSelection/TowerCoverage_BVBT_dM.pdf}{}
    \caption{ 
     Sensitivity converage by individual signal region towers (shades) or $\meffInc$-bins (dashed contours) to the BT/BV benchmark models in the
    (a) $\dire$ and $\xhalf$ grid, and (b) $\DMtw$, $\DMth$ grid. }
    \label{fig::SRdefinition::towerCoverage1}
\end{figure}

\begin{figure}[h]
  \centering
    \subfig{0.6}{figures/SRdefinition/EventSelection/TowerCoverage_3B_x12.pdf}{}
    \subfig{0.45}{figures/SRdefinition/EventSelection/TowerCoverage_3B_varx.pdf}{}
    \subfig{0.5}{figures/SRdefinition/EventSelection/TowerCoverage_BVBT_varx.pdf}{}
    \caption{ 
     Sensitivity converage by individual signal region towers (shades) or $\meffInc$-bins (dashed contours) 
     (a) to the 3B benchmark models in the $\dire$, $\xhalf$, $\DMtw$ and $\DMth$ grids,
     (b) in the $\varx$ grid, and
     (c) to the BT/BV benchmark models in the $\varx$ grid.
 }
    \label{fig::SRdefinition::towerCoverage2}
\end{figure}


\clearpage
% ------ Definition of Variables
\subsection{Discriminating Variables for Background Rejection}
While the signal region binning mainly focuses on the signal extraction,
further kinematical cuts needs to be applied for dedicated backgroud rejection.
This sub-section overviews the kinamtical variables used in the analysis for signal region definition. 
The distributions at the pre-selection are presented in Figure \ref{fig::SRdefinition::distVar1} - \ref{fig::SRdefinition::distVar2}. 
\footnote{Some additional pre-selection is applied exceptionally; the soft lepton requirement ($\pt(\ell)\in[6,35]$) for Figure \ref{fig::SRdefinition::distVar2} (b), $\meffInc>1500\gev$ for Figure \ref{fig::SRdefinition::distVar2} (b), and $\nBJetNoGev \geq3 \,\,\, \mt>125\gev$ are applied for Figure \ref{fig::SRdefinition::distVar2} (c) and (d). 
}

\paragraph{${\bf \nJet}$}
Jet multiplicity often shows a great discriminating power since the standard model processes suffer a sharp cut-off.
However one should mind that the optimum cut is significantly dependent on gluino decay modes, and also that the aggressive cut will enhance the contribution from the higher-order effects, putting the background modeling at the risk of theoretical uncertainty.
Therefore, the cut is kept moderated as means of background rejection. 

\paragraph{${\bf \met}$}
Signal events with large $\met$ reflects the presence of hard LSPs,
therefore $\met$ is very helpful in separation against the background when $\dmg$ is large.
At analysis level, this is also true for the compressed case given that the MET via ISRs is nevertheless required for the trigger sake as described above.

\paragraph{${\bf \meffInc}$} 
$\meffInc$ is the best discriminating variable against the background.
It is also notable that $\meffInc$ is highly correlated to the absolute mass splitting $\dmg$ irrespective to the relarive mass splitting with respect to the intermediate EW gauginos, therefore the same binning can be used between different towers.
%better than applying cuts on jet pt individually giving the low xsec for signal that cant afford in acceptance.


\paragraph{${\bf \mtFull}$} 
$\mtFull$ is defined by the invariant mass between lepton tranverse momentum and $\met$.
Analogous to ordinary invariant mass peaking at the mass of the parent particle, 
the end point of $\mt$ represents the parent mass.
Since SM 1-lepton process is always with a leptonically decaying $W$-boson without additional hard missing particles, the bulk component experiences a sharp cut-off in $\mt$ around $m_W = 81.4 \gev$, 
therefore the cut above $m_W$ is tremendously effective in background rejection.


\paragraph{Aplanarity}
Aplanarity \cite{Aplanarity} is a variable characterizing the 3-dimensionality of an event in terms of the final state particles. 
It is defined by the thirtial eigenvalue of the normalized momentum tensor $S$ constructed from 3-momenta of jets and leptons:
\begin{align}
  S^{\alpha \beta} & := \frac{\sum_{i \in j,\ell} p_i^{\alpha} p_i^{\beta} }{\sum_i |\bm{p_i}|^2 }, \nn \\ 
  %
  P^{-1}SP & = \left(
  \begin{array}{c c c }
    \lambda_1  & & \\
    & \lambda_2 & \\
    & & \lambda_3 \\
  \end{array}
  \right), \,\,\, \lambda_1 > \lambda_2 > \lambda_3, \nn \\
  \mathrm{Aplanarity} & := \frac {3}{2} \times \lambda_3,
  %
\end{align}
where $P$ stands for the $3\times3$ matrix diagonalizing $S$, and $\lambda_i$ are the eigenvalues of $S$.
It ranges from $0<A<1/2$. While $A=0$ corresponds to an event with jets distributed in the common plain, $A=1/2$ represents the isotropically distributed event topology.
Aplanarity is an effective discriminator after requiring tight selection in $\meffInc$ or $\met$, where the remnant SM events (particularly $\wjets$) are typically heavily kicked by hard ISRs, leading to a linear event topology in their center-of-mass frame. These events end up in a planar topology in the lab frame once getting boosted toward the beam direction, as a result populating in low aplanarity region accordingly. 
On the other hand, the decay of gluino pairs keep relatively spherical thus the aplanarity distribution tends to be rather flat, which reflects the fact that gluino is too heavy to be boosted.




\paragraph{${\bf \met/\meffInc}$}
$\met/\meffInc$ separates the backgrounds and the signals targeted by the \textbf{2J} and \textbf{High-x} where jet activity is relatively low compared with the magnitude of MET required.


\paragraph{${\bf \nJetNoGev/\lepOnePt}$}
Since the hardness of lepton and jets are positively correlated in normal processes in SM, it is relatively rare to end up in a soft lepton and hard jet activity simultaneously, while it is the case for the compressed gluino signature. A variable $\nJetNoGev/\lepOnePt$ helps visualize the different correlations, and used in the \textbf{2J} signal region towers to improve the sensitivity towards the compressed gluino signatures.


\paragraph{${\bf \mindPhiFourJet}$}
$\mindPhiFourJet$ is a variable indended to reject the remnant $\ttbar$ events after requiring tight selection of $\meffInc$ and $\met$. 
As such $\ttbar$ events typically have hard ISR jets to boost the $\ttbar$ system, the jets from $\ttbar$ decays and associated soft radiation tend to be collimated each other. Conversely, the jets from the gluino decays almost never get collimated due to the heavy mass of gluino.


\paragraph{Topness}
One of the most important background in 1-lepton analysis is di-leptonic $\ttbar$ events with a hadronically decaying tau lepton or a lepton that fails the baseline requirement. To reject those events, a $\chi^2$-based di-leptonic $\ttbar$ tagger ``topness'' has been designed in context of scalar-top search since Run1 \cite{Topness}. 
The $\chi^2$ function is defined as:
\begin{align}
& S(p_{\mathrm{W}}^x, p_{\mathrm{W}}^y, p_{\mathrm{W}}^z, p_{\nu}^z)  \nn  \\
& = \chi^2(m_{t,1}^2) + \chi^2(m_{t,2}^2) + \chi^2(m_{W,1}^2) + \chi^2(\hat{s}(\ttbar))  \nn  \\
& = \frac{  \left( m_t^2 - (p_{b,1}+p_{\ell}+p_{\nu})^2                      \right)^2   }{a_t^4}  \nn \\
& + \frac{  \left( m_t^2 - (p_{b,2}+p_\mathrm{W})^2                          \right)^2   }{a_t^4}  \nn  \\
& + \frac{  \left( m_\mathrm{W}^2 - (p_{\ell}+p_{\nu})^2                     \right)^2   }{a_\mathrm{W}^4}  \nn \\
& + \frac{  \left( 4m_t^2- (p_{\ell}+p_{\nu}+p_{b,1}+p_{b,2}+p_\mathrm{W})^2 \right)^2   }{a_{\ttbar}^4},
\label{eq:SRdefinition::topness}
\end{align}
assuming an event topology shown in Figure \ref{fig::SRdefinition::topness_diagram} where one of the leptons is totally undetected and the momentum does fully contribute to $\met$. 
It consists of four Gaussian constraints expressing the mass constraint of a top-quark and a $W$-boson, and an approximate constraint on the center-of-mass for the $\ttbar$ system ($\hat{s}(\ttbar)$) which peaks at $2m_t$. The width parameters are set to $(a_t, a_W, a_{\ttbar})=(15,5,1000) \gev$, accounting for the Breit-Wigner widths of top-quark and $W$-boson as well as the tail of $\hat{s}(\ttbar)$ distribution. Although there are three missing particles in the topology, the number of unknown degree of freedom can be reduced into 4 by combining the missing lepton ($\ell_2$) and the paired neutrino ($\nu_2$) into a single on-shell $W$-boson and imposing the vectoral sum of transverse momenta of missing particles being equal to $\met$. 
Topness is then defined as the minimum $\chi^2$ when scanning over the four DOFs ($\bm{p}_{\mathrm{W}}$ and $p_{\nu}^z$):
\begin{align}
\mathrm{Topness} := \min_{p_{\mathrm{W}}^x, p_{\mathrm{W}}^y, p_{\mathrm{W}}^z, p_{\nu}^z} \ln[S].
\end{align}
Events in the topology assumed are supposed to have solutions ($p_{\mathrm{W}}^x, p_{\mathrm{W}}^y, p_{\mathrm{W}}^z, p_{\nu}^z$) that satisfy the four constraints at the same time, however it is not necessarily the case for the other events. Figure \ref{fig::SRdefinition::topness_diagram} shows the typical separation between di-leptonic $\ttbar$ and signals, where the majority of di-leptonic $\ttbar$ resides on the lower pile while signals typically populate in the opposite one. 
Note that the di-leptonic $\ttbar$ in the higher pile are due to the fact that the energy of missing leptons or tau leptons does not entirely contribute to $\met$, violating the assumption made in Figure \ref{fig::SRdefinition::topness_diagram}. 

%%%%%%%%% diagram for illustrating topness 
%\clearpage
\figNoH[100]{SRdefinition/EventSelection/topness_diagram.pdf}
{Di-leptonic $\ttbar$ topology assumed in the topness calculation where one lepton is tagged ($\ell_1$) and the other lepton ($\ell_2$) is ``lost'' with its momentum fully contributing to $\met$. 
%The $\chi^2$s are constructed based on the three mass constraints for the top, anti-top and the W-boson decaying into $\ell_1$, as well as one pseudo-mass constraint in terms of the $\ttbar$ systems (labeled as pink circles). Topness is defined as the minimum of their summ, while scanning over the momenta space of missing particles. The degrees of freedom by $\ell_2$ and the associated neutrino ($\nu_2$) are combined into a 4-momentum $p_W$ with the mass fixed to $m_W = 81.2\gev$, and the scan is performed in terms of $p_{\mathrm{W}}^x, p_{\mathrm{W}}^y, p_{\mathrm{W}}^z$ and $p_{\nu}^z$ from $-4\tev$ to $4\tev$ respectively.
}
{fig::SRdefinition::topness_diagram}
%%%%%%%%%%%


\begin{figure}[h]
  \centering
    \subfig{0.48}{figures/SRdefinition/discVar/nJet30__Precut.pdf}{Jet multiplicity}
    \subfig{0.48}{figures/SRdefinition/discVar/lep1Pt__Precut_log.pdf}{Lepton's $\pt$}
    \subfig{0.48}{figures/SRdefinition/discVar/met__Precut_log.pdf}{$\met$}
    \subfig{0.48}{figures/SRdefinition/discVar/meffInc30__Precut_log.pdf}{$\meffInc$}
    \subfig{0.48}{figures/SRdefinition/discVar/mt__Precut_log.pdf}{$\mt$}
    \subfig{0.48}{figures/SRdefinition/discVar/LepAplanarity__Precut_log.pdf}{Aplanarity}
    \caption{ 
    Distributions of discriminating variables for reference signal and backgrous, at the pre-selection level.
    \label{fig::SRdefinition::distVar1}       
    }
\end{figure}


\begin{figure}[h]
  \centering
    \subfig{0.48}{figures/SRdefinition/discVar/nJetOverLepPt__Precut_softLep.pdf}{$\nJetNoGev/\lepOnePt$}
    \subfig{0.48}{figures/SRdefinition/discVar/metOverMeff__Precut_meff1500.pdf}{$\met/\meffInc$}
    \subfig{0.48}{figures/SRdefinition/discVar/min_dPhi_4j__Precut3B_MT125.pdf}{$\mindPhiFourJet$}
    \subfig{0.48}{figures/SRdefinition/discVar/topNess__Precut3B_MT125.pdf}{Topness}
    \caption{ 
    Distributions of discriminating variables at the pre-selection level.
    Soft lepton requirement: $\pt(\ell)\in[6,35]$ is applied for (b),
    and $\nBJetNoGev \geq3 \,\,\, \mt>125\gev$ is applied for (c) additionally. 
    \label{fig::SRdefinition::distVar2}
    }
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage		
\subsection{Cut Optimization}
The cut values for the kinematic variables introduced above are optimized.
Reference signal points are used for the optimization which are defined in Table \ref{tab::SRdefinition::refSigPointsOptm}. 
The optimization procedure proceeds as following:

\begin{enumerate}
\item The binning of $\meffInc$ is roughly decided so that the sensitivities for all the reference points in the same tower are well addressed.
\item Cuts values in other variables are then optimized by a simultaneous grid scan using machinery. The initial values are chosen based on the target mass regions of each signal region (as depicted by Figure \ref{fig::SRdefinition::towerCoverage1}-Figure \ref{fig::SRdefinition::towerCoverage2}), and the typical kinematics of such signals as shown in Figure \ref{fig::SRdefinition::kineMap_QQC1QQC1_x12}-\ref{fig::SRdefinition::kineMap_TTN1TTN1} in Appendix \ref{sec::App::kineMap}.
The sensitivity as the measure of the optimization is defined by the combined significance over the $\meffInc$-bins such as:
\begin{align}
Z_{N,\mathrm{comb.}} =\sqrt{\sum_i Z_{N,i}^2}  \label{ZNcomb} \\
\end{align}
where $Z_{N,i}$ is the significance that a single $\meffInc$-bin addresses:
\begin{align}
Z_{N,i} := S_i/\sqrt{B_i+\alpha^2 B_i^2}. \label{eq::ZNdef}
\end{align}
$S_i$, $B_i$ are respectively the signal and background yields in the $\meffInc$-bin $i$. 
$\alpha$ is relative uncertainty on the background expectation. This is fixed to $30\%$ in the study, which is the typical level of systematic uncertainty. 
The cuts between BT and BV bins in the same tower and the same $\meffInc$-bin are always set to common.

\item All the cuts including the $\meffInc$-binning are re-optimized by pertubating the best cuts found in the previous step.

%\item The optimum cuts are different between reference points in the same $\meffInc$-bins. An adjustment is therefore applied for the best compromise, as well as to avoid the over-optimization on specific signal points.

\item Another minor adjustment is done afterwards for sake of easier background estimation, where typically some of the cuts are loosened to facilitate the secure the control region statistics.
\end{enumerate}

\tab{ c c c}{
      \hline
      &   Model    & $(\mG,\mC,\mLSP)$,$(\mG,\mLSP)$ [GeV] \\
      \hline
      \hline
      \textbf{2J BV}  & & \\
      \hline
      &   QQC1QQC1 & (1550,580,550)  \\
      &   QQC1QQC1 & (1065,1025,985) \\
      &   TTN1TTN1 & (1000,915)      \\
      \hline
      \textbf{2J BT}  & & \\
      \hline
      &   QQC1BTC1 & (1400,830,800)  \\
      &   QQC1BTC1 & (1550,780,750)  \\
      \hline
      \textbf{6J BV}  & & \\
      \hline
      &  QQC1QQC1 & (1945,1105,265)  \\
      &  QQC1QQC1 & (1850,1350,850)  \\
      &  QQC1QQC1 & (1700,1300,900)  \\
      \hline
      \textbf{6J BT}  & & \\
      \hline
      &  QQC1BTC1 & (1850,1050,250) \\
      &  QQC1BTC1 & (1700,1300,900)  \\ 
      \hline
      \textbf{$\Lowx$ BV}  & & \\
      \hline
      &  QQC1QQC1 & (1700,460,60)    \\ 
      &  QQC1QQC1 & (1600,260,60)    \\
      &  QQC1QQC1 & (1700,530,500)     \\                                
      \hline
      \textbf{$\Lowx$ BT}  & & \\
      \hline
      &  QQC1BTC1 & (1700,730,700) \\
      &  QQC1BTC1 & (1700,530,500) \\
      \hline
      \textbf{$\Highx$ BV}  & & \\
      \hline
      &  QQC1QQC1 & (1800,1600,60) \\
      &  QQC1QQC1 & (1800,1460,60) \\
      &  QQC1QQC1 & (1800,1260,60) \\
      \hline
      \textbf{$\Highx$ BT} & & \\
      \hline
      &  QQC1BTC1 & (1850,1750,60)    \\
      &  QQC1BTC1 & (1850,1450,60)    \\
      \hline
      \textbf{3B}  & & \\
      \hline
      &  TTN1TTN1 &  (2000,0)     \\ 
      &  TTN1TTN1 &  (1900,800)   \\ 
      &  TTN1TTN1 &  (1500,1000)   \\
      \hline
}
{The reference signal points for each signal region to which the cuts are optimized to.}
{tab::SRdefinition::refSigPointsOptm}

Finalized definition of signal regions are shown in Table \ref{SRdefinition::regionDef2J}-\ref{SRdefinition::regionDef3B}. The $\meffInc$ distribution in the optimized signal regions are displayed in Figure \ref{fig::SRdefinition::SRmeffInc2J}-\ref{fig::SRdefinition::SRmeffInc3B} 
%for backgrounds with the reference signal points overlaid
. The segmentation of $\meffInc$-bin is found to successfully address the sensitivity in different mass region in the signal grid. \\

The optimized selection is also validated by checking the kinematic distributions in which one of the cuts is removed from the optimized signal region (``N-1 plots''). Figure \ref{fig::SRdefinition::N1plots_2JMEFFInclBV}-\ref{fig::SRdefinition::N1plots_3BMEFFIncl} in the appendix \ref{sec::Appendix::N1plots} show the N-1 plots for each signal region, where the sensitivity is calculated as function of the cut position of the removed cut. The decided cut potisions are indicated by the red arrows, which more or less accord with the optimum position for all the reference signals.



\input{tex/SRdefinition/tab_SRdefinition_noVRDB.tex}
\input{tex/SRdefinition/fig_SR_meffInc.tex}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage				
\subsection{Expected Sensitivity} \label{sec::SRdefinition::expLimit}
The limits expected by the optimized signal regions are calculated for the reference models using the simulation normalized to an integrated luminosity of $L=36.1\ifb$.
The expected exclusion limit for the \textbf{TTN1TTN1} $\dire$ grid is shown in \ref{fig::SRdefinition::expLimitTTN1TTN1}. 
The dashed lines on the left plots indicate the exclusion provided by a single $\meffInc$-bin, and the solid lines being the limit given by respective signal region towers with combined bins. 
The ultimately sensitivity provided by the combined towers are shown in the right plots. 
Since the all five towers are not completely orthogonal (\textbf{2J} and \textbf{Low-x}, \textbf{6J} and \textbf{High-x} are partially overlapped), 
there are four possible ways of combining orthogonal towers: \{\textbf{2J}, \textbf{6J}, \textbf{3B}\}, \{\textbf{2J}, \textbf{High-x}, \textbf{3B}\}, \{\textbf{Low-x}, \textbf{6J}, \textbf{3B}\}, and \{\textbf{Low-x}, \textbf{High-x}, \textbf{3B}\}.
The final result is provided using the combination giving the best expected sensitivity. 
The expected sensitivity for \textbf{QQC1QQC1} and \textbf{QQC1BTC1} are presented in Figure \ref{fig::SRdefinition::expLimitQQC1QQC1} and Figure \ref{fig::SRdefinition::expLimitQQC1BTC1}. Nice complementarity between the signal region towers and $\meffInc$-bins are demostrated. 
No suspicious structure indicating local over-optimization onto specific mass or decay models is found, ensuring the inclusive sensitivity of the analysis. 

% each SR does its best job, providing complemental coverage in terms of mass configuration
% 3B
\fig[160]{SRdefinition/expLimit/canvas_symTTN1_x12.pdf}
{Expected exclusion (95$\%$CL) for the benchmark model \textbf{TTN1TTN1}. The left plot shows the exclusion limits set by individual signal region $\meffInc$-bin (dashed lines) or a tower (solid lines). The contours in the right plot display the ultimate sensitivity provided by the combined fit. The hypothetical test will be carried out using the best performed combination in deriving the final result. }
{fig::SRdefinition::expLimitTTN1TTN1}


\begin{figure}[h]
  \centering
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_symQQC1_x12.pdf}{}
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_symQQC1_varx.pdf}{}
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_symQQC1_dM30.pdf}{}
    \caption{Proejcted expected exclusion (95$\%$CL) for the benchmark model \textbf{QQC1QQC1} onto the (a)$x=1/2$ (b)$\mLSP=60\gev$ (c) $\dmc=30\gev$ grid. The contours in the right plot display the ultimate sensitivity provided by the combined fit. The hypothetical test will be carried out using the best performed combination in deriving the final result. }
    \label{fig::SRdefinition::expLimitQQC1QQC1}
\end{figure}

\begin{figure}[h]
  \centering
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_QQC1BTC1_x12.pdf}{}
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_QQC1BTC1_varx.pdf}{}
    \subfig{0.8}{figures/SRdefinition/expLimit/canvas_QQC1BTC1_dM30.pdf}{}
    \caption{Proejcted expected exclusion (95$\%$CL) for the benchmark model \textbf{QQC1BTC1} onto the (a)$x=1/2$ (b)$\mLSP=60\gev$ (c) $\dmc=30\gev$ grid. The contours in the right plot display the ultimate sensitivity provided by the combined fit. The hypothetical test will be carried out using the best performed combination in deriving the final result. }
    \label{fig::SRdefinition::expLimitQQC1BTC1}
\end{figure}


