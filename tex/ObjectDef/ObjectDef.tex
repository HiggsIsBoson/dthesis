\chapter{Object Reconstruction and Identification}  \label{sec::objDef}
The raw detector-level information is translated into physics quantities through the sequence of particle reconstruction, identification and calibration.
Though this is partially done at the trigger level, the recorded events are further elaborated by the sophisticated off-line algorithms. 
These off-line reconstructed particles refer to ``object''. 
In this analysis, electrons, muons, jets and missing transverse energy (MET) are defined, 
and Figure \ref{fig::objDef::objDefOverview} schematizes the workflow of the formation of these analysis-level objects from the detector information via low-level objects such as tracks and vertices. 
This section will overview the procedures regarding to the object definition (reconstruction, identification, calibration etc.) for each involved object.
%algorithmもそうだが、そもそも使える素材が多い。例えばtrackが使える. standardなtrackingはtime-consumingなので（特にpileupに対してnon-linearに計算量が増えるので）triggerには今のところ使われていない

%reco/id/calibのterminologyは以下の通り
%- reco: combination of particle finding, loose particle identification and 4-momentum detemination
%- id:   dedicated separation algorithm for rejecting fake objects
%- calib.: including efficiency measurement and correction on simulation
\fig[120]{ObjectDef/objDefOverview.pdf}
{Schematic flow of the formation of analysis-level objects from the detector-level infomation. 
Black squares symbolize the procedures that dedicated off-line algorithms are working on.}
{fig::objDef::objDefOverview}

\clearpage
\section{Tracks} \label{sec::objDef::tracks}
Charged tracks are the fundamental units seeding various off-line particle reconstruction and calibration.
Standard tracks used in ATLAS refers to ID tracks, reconstructed by the hits created in the inner detector (ID).
The MS tracks for muon identification are separately reconstructed, which is described in Sec. \ref{sec::objDef::muons::reco}.
The reconstruction algorithm mainly consists of following four steps (the detail can be found in \cite{130_trackingRun2}): 

\begin{itemize}
\item Based on the 3-dimensional position information and the readout charge associated to each hit in the silicon detectors, 
spatial charge profile is constructed. 
Hits from the same particle traverse are identified and merged, using a combination of a pattern recognition technique called connected component analysis (CCA) \cite{CCApatterRecog} and a neural network classifier \cite{NNClustering}.
Seed tracks are then reconstructed from three aligned clusters.

\item The seed tracks are extrapolated outward,
and the association with the TRT hits are tested using the Kalman Filter \cite{133_KalmanFitter} characterized by five tracking parameters,
with a pion track hypothesis assuming the MIP energy loss in the ID material.

\item If the first pattern recognition fit fails, a second fit is attempted based on the electron hypothesis where the energy loss at each hit surface is allowed, recovering the electrons with significant bremsstrahlung.

\item Successful tracks from the Kalman Filter are rerun using the ATLAS Global $\chi^2$-Track Fitter \cite{157_ATLASGlobTrackFitter}.
A pion or an electron hypothesis is used, depending on which was used successfully in the previous step.

\end{itemize}
A further refined algorithm (Tracking In Dense Environment; TIDE) is used from Run2 \cite{130_trackingRun2}, 
to cope with the denser particle environment due to the increased pile-up and collision energy.
The performance is shown red lines in Figure \ref{fig::objDef::trackEff1} where the efficiency is shown as function of the promixity to the cloest jet. Typically over $95\%$ of efficiency is maintained. \\ 

%Standard trackingはjet中のpionやelectronを想定してこのように内側のdetectorで作ったseedを外側に外挿してfindされるが, 
%外側(TRT)でseedを作って内側に外挿してくalgorithmも存在する。これはconverted photonをIDするためのalgorithmであり, photon IDに使われる.
%%%%%%%%%%
\figNoH[110]{ObjectDef/trackEff1.pdf}
{Reconstruction efficiency of tracks in jets as function of anglular distance with respect to barycenter of the jet \cite{130_trackingRun2}. Red points corresponds to the tracking algorithm used from Run2.
}
{fig::objDef::trackEff1}
%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Primary Vertices} \label{sec::objDef::PV}
The positions of $pp$-collisions are identified using the reconstructed ID tracks. These vertices refers to ``primary vertices'' (PV) 
\footnote{The ``primary'' is meant to distinguish against the vertices generated by late decaying particles known as ``secondary-vertices''.}
and are important for providing reference point of re-tracking and objects calibrations.
PVs are reconstructed using the Iterative Vertex Finding algorithm \cite{134_vertexing_Run1}\cite{135_vertexing_Run1_2012}, identifying the peak in the $z$-distribution of extrapolated tracks. The position of identified PVs are further elaborated using the adaptive vertex fitting algorithm \cite{136_adaVertexFit}.
The ID tracks are then re-fit taking advantage of these reconstructed PVs. The re-tracking procedure in principle lasts until all the tracks are associated to either of the PVs. PVs with less than two associated tracks are discard.  
%Figure \ref{fig::objDef::vertexEff} shows the simulated reconstrution efficiency for PVs under the Run2 condition.
Though $10\sim30$ PVs are reconstructed per bunch crossing, usually there is only one PV causing meaningful scattering, for instance firing the trigger. This PV is referred by the ``hard-scatter'' vertex  identified as the PV with the highest sum of associated track $\pt$, and the position is used as the origin for object calibration. \\

%\figNoH[160]{ObjectDef/vertexEff_136.pdf}
%{Efficiency of primary vertex detection.}
%{fig::objDef::vertexEff}



%%%%% 4,2,0 is Run1 parameters
\section{Topo-clusters} \label{sec::objDef::TopoCluster}
Topo-cluster (or TC) is the basic unit of energy measurement in calorimeter and used as the input for jet clustering  (Sec. \ref{sec::objDef::jets::clustering}) as well as in computing the isolation variables (Sec. \ref{sec::objDef::fakeAndIsolation}). 
It is formed by three-dimensionally grouping the cells with significant energy deposit.
The clustering algorithm proceeds as follow \cite{138_topoClustering_Run1}:
\begin{itemize}
\item Find cells with energy deposit exceeding $4\sigma$ from the expected noise level. These cells are identified as seed cells.
\item Neighboring cells touching the boundary of seed cells with energy deposit exceeding $2\sigma$ from the expected noise level are added to the cluster and become the seed cells for the next iteration.
\item Iterate the previous step until the cluster stops growing.
\item Split the cluster if there are two or more local maxima with $E_{\mathrm{cell}}>500\mev$ inside the TC.
%how?
\end{itemize}
EM-scaled energy is assigned for TCs. \\

%Figure \ref{fig::objDef::TC} shows the 
%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/TCnoiseLv_mu30.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/nTC.pdf}{}
%    \caption{ (a) Pile-up dependence of noise level in calorimeter. (b) Number of reconstructed topo-cluster. 
%      \label{fig::objDef::TC} }
%\end{figure}
%%%%%%%%%%


\clearpage
\section{Electrons} \label{sec::objDef::electrons}
%Figure \ref{} schematizes the electron interaction with detectors and the involved detector system electron in the reconstruction and identification.

\subsection{Reconstruction} \label{sec::objDef::electrons::reco}
The electron reconstruction algorithm proceeds as following (widely referred from \cite{156_ElectronEffMeas_2015data}): 

\begin{itemize}
\item \textbf{Reconstruction of a EM cluster from energy deposit in the EM calorimeter.} \\
This is done by the sliding window algorithm. Cells in the all four layers in the EM calorimeter are grouped into $\eta\times\phi$ towers of $0.025\times0.025$, and a window defined by the $3\times5$ units of towers are slided over the detector. A local maximum in the window energy above $2.5\gev$ is identified an EM the cluster. About $95\%$ ($99\%$) of clustering efficiency are maintained with electrons in $\ET=7 \gev$ ($>15 \gev$).

\item \textbf{Track-Cluster matching and refitting.} \\
The EM cluster is matched with a ID track reconstructed based on the electron hypothesis (see Sec. \ref{sec::objDef::tracks}) in the angular distance $\Delta R = \sqrt{(\Delta \eta)^2+(\Delta \phi)^2}$.
%with $|\Delta \eta|<0.05$ and $-0.2<\Delta \phi<0.05$ 
%where positive $\Delta \phi$ corresponds to case in which the fitted track is bending away from the cluster barycenter.
Closest track in $\Delta R$ with respect to the EW cluster is chosen if multiple tracks satisfy the matching criteria.
%if failed, rescale the track energy and test if $|\eta|<0.05$ and $-0.1<\phi<0.05$  (trajectoryはどうやって変える？)
The matched track enjoys further correction by a re-tracking using the Gaussian Sum Fitter (GSF) \cite{158_GSF} algorithm in which Bremstralung is dedicated modeled.

\item \textbf{Energy determination.} \\
The information from track momentum and calibrated EM cluster energy are combined using a multivariate algorithm \cite{161_egammaCalibRun1}.
 %achieving the best available energy resolution.
%低い方だとtrackの方が強い.. とかも
\end{itemize}

The reconstruction efficiency is measured by $Z\ra ee$ events. Figure \ref{fig::ObjDef::electronRecoEff} presents the result together with the prediction by MC. Over $96\%-98\%$ of efficiency is achieved for $\ET>20\gev$.

%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/electronRecoeff_pt_156.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/electronRecoeff_eta_156.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%


\fig[160]{ObjectDef/electronRecoEff_156.pdf}
{ Reconstruction efficiency simulated (grey) or measured (blue) using $Z\ra ee$ events \cite{156_ElectronEffMeas_2015data} as function of (left) $\ET$, and (right) pseudo-rapidity of reconstructed EM clusters.}
{fig::ObjDef::electronRecoEff}


\clearpage
\subsection{Identification} \label{sec::objDef::electrons::id}
Reconstructed electron candidates are dominated by backgrounds from pions in the jets, particularly when they are low-$\ET$. Therefore, a powerful identification algorithm is employed, using a multi-dimensional likelihood exploiting all the relevant detector information. 17 variables in total are input into the likelihood, including the longitudinal or transverse EM shower profile and the number of high-threshold hits in TRT and so on. The full list of input variables is found in \cite{156_ElectronEffMeas_2015data}.
The discriminant is given by a form of likelihood ratio, which is known to generally provide the best separation between the hypotheses \cite{NPLemma}.
The signal and background PDF is modeled using the simulated events of $Z\ra ee$ and di-jet respectively.
%great advantage over the cut-based id since each variable 
%こいつはHLT electron triggerにも入っててon-lineのperformanceも上がったし, 
%off-lineとのsynergyによってturn-onもバリ改善した
Figure \ref{fig::ObjDef::electronIDEff_156} shows the efficiency of the electron identification.
Multiple working points are available with different cut value in the likelihood ratio. 
In the analysis, two working points; \textttb{Loose} and \textttb{Tight} are used, corresponding about $90\%$ and $70\%$ of efficiency at $\ET = 30\gev$. \\


\fig[160]{ObjectDef/electronIDEff_156.pdf}
{Electron identification efficiency as function of (left) $\ET$, or (right) pseudo-rapidity of reconstructed electron candidates \cite{156_ElectronEffMeas_2015data}. $Z\ra ee$ events are used for both MC and data.}
{fig::ObjDef::electronIDEff_156}


%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%



%\clearpage
\subsection{Calibration} \label{sec::objDef::electrons::calib}
The electron calibration consists of several different procedures.
Different tretments are applied between simulation and data.
The workflow is illustrated in Figure \ref{fig::objDef::elecCalibFlow}.

\begin{description}
\item \textbf{A MC-based calibration using BDT} \\
Though the energy of cell deposit in EM calorimeter and electron cluster is already calibrated in EM scale, 
it still suffers from the residuals due to the energy loss in the material upstream of the calorimeter, energy leakage out of the envelope of the cluster or the EM calorimeter, and so on.
A multi-variate algorithm (BDT regression) is employed to account for these numerous effects and correct them. 
This is done by constructing a mapping function to the true energy from the raw energy as well as other information such as the angular position, shower profile, and the hit information from the other auxiliary detectors such as hadronic calorimeter.
The full detail can be found in \cite{161_egammaCalibRun1} \cite{egammaCalib2015}. 

\item \textbf{Longitudinal calorimeter layer inter-calibration} \\
The scales along longitudinal layers is equalized in data with respect to simulation, prior to the determination of the overall energy scale, in order to ensure the correct extrapolation of the response in the full $\pt$ range. This is only applied in data.

\item \textbf{Non-uniformity correction in $\phi$} \\
A set of corrections are applied to data, to account for the $\phi$-inuniformity due to various on-line instrumental effects that are not included in simulation, such as non-optimal high voltage setting, geometrical effects (e.g. inter-module widening) or biases in the LAr calorimeter electronics calibration.

\item \textbf{Residual scale calibration on data / Resolution correction on simulated electrons.}  \\
The residual mis-calibration in data is corrected by shifting the energy scale so that it agrees with the expectation from simulation. This is done by comparing the mass of Z-peak in $Z \ra ee$ events.

It is found that the resolution in data is slightly worse than that in simulation using the same event sample.
The corrections are derived and applied to simulation to match the data. 
\end{description}
Numerous minor corrections follow additionally, which is detailed in \cite{161_egammaCalibRun1}. 
The calibration is widely validated using the data events of $J/\psi \ra e e$ and $Z\ra ee$. \\

%\cite{162_ECALTB_ATLAS}

\fig[160]{ObjectDef/elecCalibFlow.pdf}
{Flow chart of electron calibration applied for MC and data \cite{161_egammaCalibRun1}.}
{fig::objDef::elecCalibFlow}

%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/electronReso_161.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/electronResoUnct_161.pdf}{}
%    \caption{ (a) Energy resolution after the calibration (solid line) and resolution uncertainty (band).  (b) Breakdonw of   
%     \label{fig::objDef::electronReso} }
%\end{figure}
%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Muons} \label{sec::objDef::muons}
\subsection{Reconstruction} \label{sec::objDef::muons::reco}
Muon tracks are reconstructed independently from ID, referred as MS-tracks. 
The tracking begins with finding the hits inside each MDT/CSC chamber and forming small track segments per chamber. 
A Hough transform is employed to convert the bending detector plane geometry into flat plane. A straight-line fit are then performed on the flattened plane for the track segments. 
The hits in RPC and TGC are used to determine the coordinate orthogonal to the MDT/CSC detector plane. The search algorithm employ a loosened requirement on the compatibility of the track and the hits, to account for the muon energy loess by interaction with material.\\

The trajectory and momentum of muons are decided by a synergy between the reconstructed MS track and the measurement by the other detectors.
There are four different schemes of the combination \cite{165_muonPerf2011_2012}:
\begin{description}
\item \textbf{Combined muons:} 
A MS track is matched to a reconstructed track in the ID, and the measurements of the momenta are statistically combined.

\item \textbf{Segment-tagged muons:} 
  A fragmet of MS track is matched with an ID track, with the momentum taken from the ID track.

\item \textbf{Standalone muons:} 
  MS tracks found outside the ID acceptance ($2.5 < |\eta| < 2.7$), with the momentum quoted from the MS track.

\item \textbf{Calorimeter-tagged muons:}
  A special type of reconstruction dedicated to muons traveling to the inactive “crack of the MDT at $|\eta|<0.1$.
  The ID tracks with $\pt>15\gev$ associated calorimeter deposit consistent with a minimum ionizing particle are tagged, with the momentum of ID track.
\end{description}
In this analysis, the combined muons is always in defining muons, while the segment-tagged muons are used for correcting the MET calculation as described in Sec. \ref{sec::objDef::met}.\\


%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%

\subsection{Identification} \label{sec::objDef::muons::id}
Additional identification requirements are imposed to purify the sample of reconstructed muons.
Cuts on variables listed in Table \ref{tab::objDef::muonID} are applied.
\tab{c|c}
{
\hline
Variable & Description \\
\hline
\hline
$\sigma(q/p)$ & Fitting error of a tracking parameter $q/p$ associated with the quality of measurement. \\
\hline
 $\rho'$ &       $\pt$ difference between ID and MS track normalized by the $\pt$ of the combined track. \\
\hline
$\chi^2$ &   
  A generic measure of fit quality defined as normalized $\chi^2$ of the combined track fit. \\
\hline
}
{Variables used for the muon identification selection.}
{tab::objDef::muonID}
The \textttb{Medium} working point defined in \cite{166_muonPerformance2015data} is used throughout the analysis, 
where only $\sigma(q/p)<7$ is required.  
Figure \ref{fig::ObjDef::muonRecoIDEff} summarizes the performance of reconstruction and ID for muons.\\

%%%%%%%%%
\figNoH[160]{ObjectDef/muonRecoIDEff_166.pdf}
{ Simulated / measured efficiency for reconstruction and identification of muons, using $J/\psi\mu\mu$ and $Z\ra\mu\mu$ events \cite{166_muonPerformance2015data}.}
{fig::ObjDef::muonRecoIDEff}


%%%%%%%%%%
%\begin{figure}
%  \centering
 %   \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%



\subsection{Calibration} \label{sec::objDef::muons::calib}
As the momentum of a muon track is already well-representing the particle-level momentum of the muon, 
the scale calibration only subjects to a series of minor corrections, accounting for the imperfect knowledge on the magnetic field integral inside the detector, the material profile between the interaction point and the MS and so on. \\

The momentum correction is performed on each muon in MC based on the formula below \cite{165_muonPerf2011_2012}:
\begin{align}
\pt^{\mathrm{Cor.}} = \frac{ s_0  + \pt^{\mathrm{MC}}  (1+s_1) } {1+ \Delta r_0  g_0  + \Delta r_1 
 \pt^{\mathrm{MC}} g_1  + \Delta r_2 \left( \pt^{\mathrm{MC}} \right)^2  g_2} 
\end{align}
where $\pt^{\mathrm{MC}}$ and $\pt^{\mathrm{Cor.}}$ respectively represent the momentum before and after the correction, and $g_m (m=0,1,2)$ are random numbers generated by an uniform PDF ranging from 0 to 1.
Numerator corresponds to the scale correction, and denominator is responsible for the resolution correction. The parameterization of denominator is based on the fact that muon resolution obeys a $\pt$ dependence of:
\begin{align}
\frac{\sigma(\pt)}{\pt} = \frac{a}{\pt} \oplus b \oplus c \cdot \pt.
\end{align}
%
The coefficients $s_i$, $\Delta r_i$ are determined bin-by-bin in $(\eta,\phi)$, 
by applying a template fit on $J/\psi\ra \mu\mu$ and $Z\ra \mu\mu$ events in data. \\

%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
 %   \caption{ (a)  (b). 
 %     \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Jet} \label{sec::objDef::jets}
%
\subsection{Jet Clustering} \label{sec::objDef::jets::clustering}
Jet reconstruction employs the anti-$k_{\mathrm{T}}$ algorithm \cite{141_antiKt} using the topo-clusters (TCs) calibrated with EM scale as input.
The basic step of the algorithm is to merge the proximate two TCs based on a distance measure defined by:
\begin{align}
d_{i,j} & = \min(p_{T,i}^{-2},p_{T,j}^{-2}) \frac{\Delta R^2_{i,j}}{r^2} 
\end{align}
where $i$ and $j$ denote the index of TCs, and $\Delta R^2_{i,j}$ is the angular distance between them. $p_{T,i}$ denotes the transverse energy of TC $i$.
$r$ is the cone parameter dictating the typical size of resultant jets, which is set to $r=0.4$ in the analysis.
The two TCs with the smallest $d_{i,j}$ are merged in each step, and the iteration continues until:
\begin{align}
\min_{i,j} \left[ d_{i,j} \right] > \min_{i} \left[ p_{T,i}^{-2} \right].
\end{align}
The anti-$k_{\mathrm{T}}$ jet clustering is characterized by the negative power index on $\pt$ in the metric $d_{i,j}$, 
where soft clusters are always added to hard components instead of being merged with the other soft cluster.
This results in a well boundary behavior of jets, giving an insensitive nature to the soft jet component on which perturbative QCD does not provide robust prediction. 
This so-called collinear- and infrared-safety is an extremely welcomed feature for jet clustering
since it allows one to straightforwardly compare the theory and data,
on which the jet calibration significantly relies.
%%% merit of antikt
% theory base calib -> ok
% MC is reliable
%

%FastJet package [142]

%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%


%%%%%%%%%
\subsection{Energy Calibration} \label{sec::objDef::jets::calib}
As the energy of TC is calibrated in the EM scale, clustered jet needs extra calibration to account for the hadronic interaction activity. Particle-level jets in simulated events (referred as ``truth jets'') are used for the reference of the truth energy. They are clustered by the same algorithm (anti-$k_{\mathrm{T}}$, $r=0.4$) using only stable, final-state particles as input. The input particles are required to have a life-time of $c\tau > 10 \, \mathrm{m}$ . Muons, neutrinos, and particles from pile-up activity are excluded. Truth jets with $\pt>7\gev$ and $|\eta|<4.5$ are used for the calibration. In simulated events, corresponding detector-level jets can be found by geometrically matching in  terms of the $\Delta R := \sqrt{(\Delta \eta)^2+(\Delta \phi)^2}$ \\

A series of dedicated calibration procedures is employed
aiming to restore the energy to that of the truth jets reconstructed at the particle-level energy scale. It mainly proceeds as following stages (detailed in \cite{144_JESmeas_2015data}):


%%%%%%%%
\begin{description}
\item \textbf{Origin correction} \\
Angular coordinate assigned to each topo-cluster is based on the origin defined by the designed IP position with which the actual hard-scatter vertex is displaced in $z$-axis direction. The jet orientation is recalculated based on the refined origin defined with the reconstructed primary vertex that the jet is associated with (see \cite{JESmeas_unct_Run1_inclOC}). 

%%%%%%%%
\item \textbf{Pileup subtraction} \\
The contribution of particles from pile-up jets is removed using the method of area-based density subtraction \cite{145_areaBasedPUsub}:
\begin{align}
\pt^{\mathrm{corr.}} = \pt^{\mathrm{reco.}} - \rho \times A,
\label{eq::PUresidual}
\end{align}
where $\pt^{\mathrm{reco.}}$ and $\pt^{\mathrm{corr.}}$ are the jet transverse momentum before and after the correction respectively. $A$ is the jet area defined by the area that energy deposit distributes in $\eta-\phi$ plane calculated using the ghost-association \cite{143_JetFindingReview}. $\rho$ is the average $\pt$ density from the contribution of pile-up jets. The idea is to treat the pile-up as an uniform noise level over the detector, and the contribution is proportional to the area the jet is overlaying to it. \\

There are residual pile-up dependencies found to be linear in terms of the number of reconstructed primary vertices ($N_{\mathrm{PV}}$) and the average number of interactions per bunch crossings ($\mu$). These are corrected by:
%These accounts for the underestimation by the area-based subtraction on the ``in-time'' and ``out-of-time'' contribution respectively. 
\begin{align}
\pt^{\mathrm{corr.}} = \pt^{\mathrm{reco.}} - \rho \times A - \alpha(\pt,\eta)  \times (N_{PV}-1) - \beta(\pt,\eta) \times \mu,
\label{eq::PUresidual}
\end{align}
where the linear coefficients $\alpha$ and $\beta$ are determined using the simulation as function of $\pt$ and $\eta$ of the jet.
%Figure \ref{}

%%%% NEED TO CORRECT

%%%%%%%%%
%\figNoH[160]{ObjectDef/PUrejection_144.pdf}
%{ Residual dependence of jet $\pt$ on pile-up; (a) number of reconstructed PV, and (b) average   \cite{144_JESmeas_2015data}.}
%{fig::ObjDef::PUrejection_144}



%%%%%%%%
\item \textbf{MC-based calibration} \\
The main calibration is provided by comparing the energy (or $\pt$) of detector-level jets to the corresponding truth jets in the simulated di-jet events from \pythia. The response functions $R_{\pt}, R_\eta$ are defined by:
\begin{align}
R_{\pt} (\pt,\eta) := \left< \frac{\pt^{\mathrm{reco.}}}{\pt^{\mathrm{truth}}} \right>, \,\,\,\,\,\,\,\,
R_\eta  (\pt,\eta) := \left< \frac{\eta^{\mathrm{reco.}}}{\eta^{\mathrm{truth}}} \right>, 
\label{eq::jetResponse}
\end{align}
calculated in various $\pt$ and $\eta$ bins, 
and are applied for the detector-level jets so that the energy and $\eta$ are adjusted to the particle-level scale. The conversion from the EM scale to the hadronic scale is mainly done in this stage.
%%%%%%%%%%
\begin{figure}
  \centering
    \subfig{0.48}{figures/ObjectDef/jetResponse_pt_144.pdf}{}
    \subfig{0.48}{figures/ObjectDef/jetResponse_eta_144.pdf}{}
    \caption{ Response functions; (a) $R_{\pt}$; (b) $R_\eta$ defined in Eq. \ref{eq::jetResponse} before the MC-based calibration. \cite{144_JESmeas_2015data}
      \label{fig::objDef::jetResponse} }
\end{figure}
%%%%%%%%%%





%%%%%%%%
\item \textbf{Global Sequential Calibration} \\
While only the topo-clusters level information is used for the jet energy determination so far, 
further improvements are achieved by applying corrections exploiting the global detector information from the calorimeter and muon spectrometer, as well as the reconstructed tracks from the inner detector. 

The procedure involves 5 independent stages, referred as the Global Sequential Calibration (GSC) \cite{140_jetEneMeas_TCcalib}, killing residual dependence of jet energy scale on the number of associated tracks or the spatial energy profile of the jet and etc. 

The most important function of the GSC is adding robustness against varying jet flavors in jet energy measurement, in particular between quark-initiated jets and gluon-initiated.


%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
 %   \subfig{0.48}{figures/ObjectDef/.pdf}{}
 %   \caption{ (a)  (b). 
 %     \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%




%%%%%%%%%
\item \textbf{Residual in-situ calibration} \\
A residual calibration is derived by the in-situ measurements applied only to data, 
accounting for the differences in the jet response between data and MC simulation.
%Such differences arise from the imperfect description of the detector response and detector material in MC simulation, as well as in the simulation of the hard scatter, underlying event, pile-up, jet formation, and electromagnetic and hadronic interactions with the detector. 
The differences is quantified using data events of $\gamma+\mathrm{jet}$ and $Z\ra \mu\mu + \mathrm{jet}$,
by balancing the $\pt$ of a jet against the well-measured counterpart objects as reference. \\
%Similar examination are also performed on di-jets events, using the balancing technique

\end{description}





%%%%%%%%%
\subsection{Flavor Tagging} \label{sec::objDef::jets::btag}
Hadron jets originating from $b$-quarks can be exclusively identified 
by taking advantage of the long lifetime ($c\tau\sim 450 \um$) of $b$-hadrons,
creating distinct secondary decay vertices. 
Four independent sub-algorithms (IP2D, IP3D, SV, JetFitter) exist addressing unique $b$-finding power. 
Their outcomes are combined by inputting into a BDT classifier (MV2), and the output is used as the final discriminant. Each sub-algorithm works as following (widely referred from \cite{150_bTag_Run2_exp} \cite{151_bTag_Run2_perf} \cite{bTag_Run2_2015data}): 

\paragraph{Impact parameter based algorithm: IP2D and IP3D}
IP2D and IP3D are the likelihood based classifiers using the impact parameter information of tracks associated to the jet. 
The track-level likelihood is defined in terms of the transverse impact parameter $d_0$ and its error $\sigma(d_0)$ (and longitudinal impact parameter $z$ for the case of IP3D), and modeled by MC respectively for $b$-jets and light-flavor jets. The jet-level likelihood is calculated by taking the product over the track-level likelihoods of associated tracks to the jet.
The IP2D (IP3D) is then defined by the likelihood ratio between the $b$-jet and light-flavor jet hypothesis.


\paragraph{Secondary vertex finding algorithm: SV}
The SV is an algorithm \cite{152_SV} explicitly exploring a secondary vertex. 
After a set of qualification requirements on tracks in the jet, remained seed tracks are paired testing the consistency with the two-track vertex hypotheses. Found vertices consistent with the decays of other long-lived particles (such as $K_s$ or $\Lambda$), photon conversions or hadronic interaction with a material are rejected. As further requirements, the sum of the two impact parameter significances of the two tracks is required greater than 2, and vertices with the invariant masses exceeding $6 \gev$ are removed given the masses of the $b$- or $c$-hadrons. 
Vertex with the highest invariant mass is chosen if multiple candidates are found. %%%(要出典)


\paragraph{Decay chain multi-vertex algorithm: JetFitter}
\textttb{JetFitter} \cite{153_JetFitter} is a kinematic fitting algorithm, exploiting the topological structure of weak $b$- and $c$-hadron decays inside the jet and attempt to reconstruct the full $b$-hadron decay chain. Using the Kalman Filter \cite{133_KalmanFitter}, JetFitter finds a common line to which the PV and the bottom and charm vertices belong, approximating the $b$-hadron flight path, as well as their positions. The notable advantage of this approach is that the vertices of $b$- and $c$-hadron can be reconstructed, even if only a single track is associated to any of them.

\paragraph{Combinating algorithm: MV2 }
A Boosted Decision Tree (BDT) is used to combine the output from the four algorithms.
The input variables includes
the likelihood values from IP2D and IP3D,
properties of reconstructed secondary vertex (mass, position etc.) and the associated tracks providing by SV,
and the information of fitted vertices including subsequent decays of $b$-hadrons from JetFitter.
The full list can be found in \cite{150_bTag_Run2_exp}. \\

The output distribution and the performance is preseneted in Figure \ref{fig::objDef::MV2c}.
Although the input information between the algorithms is highly correlated, 
it is shown that the combined algorithm drastically outperforms over either single algorithm. \\

Multiple working points are defined to provide different relative discrimination power against light-flavor jets and $c$-jets.
For example, MV2c10 (MV2c20) are designed to address more rejection power towards $c$-jets, trained using the background sample with light-flavor jets admixtured with $c$-jets by $10\%$ ($20\%$). 
The MV2c10 working point is used in the analysis. \\



%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%



\figNoH[160]{ObjectDef/MV2c_150.pdf}
{Left distributions present the output BDT score (MV2c20) of the signal ($b$-quark jets) and background (light-flavor and $c$-quark jets) samples. The middle and right curves respectively show the signal efficiency vs light-flavor jet rejection, and vs $c$-jet rejection.
 \cite{150_bTag_Run2_exp}}
{fig::objDef::MV2c}


%b-jetはsemi-leptonic decayでneutrinoが出るので通常resolutionが悪め
%calib?


%%%%%%%%%
%\clearpage
\subsection{Pile-up Jet Tagging and Rejection} \label{sec::objDef::jets::JVT}
\newcommand{\pv}{\mathrm{PV}}
\newcommand{\pttk}{\pt^{\mathrm{trk}_k}}
\newcommand{\pttl}{\pt^{\mathrm{trk}_l}}
Significant fraction of reconstructed jets are originated from pile-up, particularly when they are low-$\pt$.
In order to suppress the contamination, a pile-up jet rejection is applied using the Jet Vertex Tagger (JVT) discriminant \cite{155_JVT} exploiting the vertex information.  \\

%\clearpage
JVT is based on a 2D-likelihood function in terms of the corrected Jet Vertex Fraction (corr. JVT) and $R_{\pt}$:
\begin{align}
\mathrm{corrJVF} & := \frac{ \sum_k \pttk (\pv_0)  }{\sum_l \pttl (\pv_0) + \sum\pt(\mathrm{PU})/ (\kappa \cdot n_{\mathrm{trk}}^{\mathrm{PU}} )  }
,  \,\,\,\,\,\,\,\,  \sum\pt(\mathrm{PU}) := \sum_{n \ge 1} \sum_k  \pttk (\pv_n)  \nn \\
R_{\pt} & := \frac{\sum_k \pttk (\pv_0) }{\pt^{\mathrm{jet}}},
\end{align}
where $\pv_0$ denotes the hard-scatter vertex and $\pv_j (j \ge 1)$ are the other primary vertices presumably due to the pile-up interaction. 
%$n_{\mathrm{PU}}$ is the total number of pile-up tracks per event with the scaling factor $\kappa = 0.01$ determined by correlation with nl l pT (PVn) and ntrk . 
JVF (Jet Vertex Fraction) was a variable originally used for the pile-up suppression in Run1 \cite{JVF} defined by the fraction of charged tracks associated to the hard-scatter vertex:
\begin{align}
\mathrm{JVF} := \frac{ \sum_k \pttk (\pv_0)  }{ \sum_l \pttl (\pv_0) + \sum\pt(\mathrm{PU}) }.
\end{align}
While the performance of JVF is sensitive to the pileup since $\sum\pt(\mathrm{PU})$ scales linearly according to number of pileup, $\sum\pt(\mathrm{PU})$ is divided by the number of PU tracks $n_{\mathrm{trk}}^{\mathrm{PU}}$ in the corrJVF to kill the linear dependency, together with the scale factor $\kappa=0.01$ restoring the absolute normalization of the PU term.
$R_{\pt}$ is the charged energy fraction in the jet, designed to address to the jets with small number of tracks leading to low corrJVF value.
A 2D-likelihood profile in terms those two variables is respectively modeled for hard-scatter jets and pile-up jets, and the JVT is defined as likelihood ratio. \\

Figure \ref{fig::objDef::JVTdist} demostrates the typical separation.
The JVT selection JVT$>0.57$ is applied for jets with ($20 \gev < \pt< 60\gev$ and $|\eta|<2.4$), in which the pile-up jets dominantly populates.  \\


% performance, (eff, rej)
%

\figNoH[160]{ObjectDef/JVTdist_155.pdf}
{Left two plots display the distribution of the input variables of JVT; corrJVF and $R_{\pt}$. corrJVF$=-1$ represents jets with no associated tracks. The right plot is resultant output likelihood score,  JVT  \cite{155_JVT}.
}
{fig::objDef::JVTdist}

%\figNoH[80]{ObjectDef/JVTeff_155.pdf}
%{JVTeff. \cite{155_JVT}}
%{fig::objDef::JVTeff}



%%%%%%%%%%
%\begin{figure}
%  \centering
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/.pdf}{}
%    \caption{ (a)  (b). 
%      \label{fig::objDef::} }
%\end{figure}
%%%%%%%%%%



%%%%%%%%%
\clearpage
\section{Overlap Removal between the Reconstructed Objects} \label{sec::objDef::OR}
Electrons, muons and jets are reconstructed in parallel, 
allowing the ambiguity that a single particle is reconstructed or identified as multiple objects simultaneously (for instance, an electron is typically reconstructed both as an electron object and a jet). 
\footnote{The ``overlap removal'' procedure is purposely left to users, to accommodate various preference in object selection between analyses.}
A sequence of ``overlap-removal'' procedure is applied to resolve the double-counting, based on the angular distance $\Delta R = \sqrt{\Delta\eta^2+\Delta\phi^2}$ between them. \\
 
The algorithm begins with the electron-jet overlap removal.
Any light-flavor jet \footnote{A working point with $85\%$ efficiency is used for the $b$-tagging in the overlap removal, while 77$\%$ efficiency working point is used for the $b$-jet selection in the analysis, in order to save as many $b$-jets as possible in the stage.} 
reconstructed within $\Delta R < 0.2$ with respect to identified electrons is rejected.
The electron is otherwise removed if the overlapping jet is $b$-tagged jet, 
to avoid rejecting $b$-jets due to the non-prompt lepton nearby caused by the decays of $b$-hadrons. Next, to remove bremsstrahlung from muons followed by a photon conversion into electron pairs, electrons lying within $\Delta R < 0.01$ of a preselected muon are discarded.  
%
Subsequently, the contamination of muons from heavy-flavored hadron decays is suppressed by removing muons that lie within $\Delta R < \min(0.04 + (10 \gev)/\pt(\mu), 0.4)$ of any remaining jet, or within $\Delta R < 0.2$ of a $b$-tagged jet or a jet containing more than three tracks with $\pt > 500 \mev$.
In the former case, the $\pt$-decreasing angular separation mitigates the rejection of energetic muons close to jets in boosted event topologies. Finally, jets reconstructed within $\Delta R < 0.2$ of remaining electrons or muons are excluded. \\

The identification of hadronically decaying taus and photons are not exploited in the analysis, since they are not explicitly used as objects in event selections. Instead, those with sufficiently high transverse momentum can pass the jet reconstruction and the JVT requirement, treated as jets in the analysis. \\
%%% table?


%%%%%%%%%
\clearpage
\section{Fake Leptons and the Isolation Requirement} \label{sec::objDef::fakeAndIsolation}
Light-flavor leptons (electrons or muons) produced in LHC subject to two types; ``prompt leptons'' directly originated from the hard scattering via decays of real and virtual gauge bosons; ``non-prompt leptons'' generated via decays of long-lived particles such as heavy flavor hadrons or tau leptons, or pair creation of photons (mostly stemming from $\pi_0$ in jets). The leptons interested in the new physics or EW physics always subject to the prompt leptons, while non-prompt leptons are trivial and often disturbing. There are also a type of reconstructed leptons by wrongly identified pions in jets. In the thesis, these unwilling leptons (non-prompt leptons and wrongly identified pions) are collectively referred as ``fake leptons''. There are couple of requirements designed for rejecting them, which are described in the following. 

\paragraph{Impact parameter requirement}
Non-prompt leptons are generated in relatively displaced position with respect to the primary vertex, therefore the information of transverse impact parameters is helpful rejecting them. The selection used in the analysis is as Table \ref{tab::ObjDef::impactPar}.
While the $d_0$ and $z_0 |\sin{\theta}|$ of prompt-leptons populate close to 0, 
those for non-prompt leptons result in a wider distribution, leading many of them to be rejected.
%
\tab{c|c|c}
{
\hline
                                     &   Electron &   Muon \\
\hline
\hline
$|d_0|/\sigma(d_0)$                 &   $<5$       &   $<3$   \\
$z_0|\sin{\theta}|$   &   $<0.5$ mm     &   $<0.5$ mm  \\
\hline
}
{
Impact parameter requirements used in the analysis. $d_0$ and ($z_0$) is the transverse (longitudinal) impact parameter.
$\sigma(d_0)$ is the fitting error of $d_0$ in the track fit.
}
{tab::ObjDef::impactPar}
%
%%% fig?
%
%
\paragraph{Isolation}
While fake leptons generally fly closely by jets because of their origin,
the path of flights of prompt-leptons rarely overlap with other particles.
%Relatively higher jet activity around fake leptons is expected, 
Therefore, the isolation requirement with respect to proximate cluster or tracks provide significant rejecting power of fake leptons. 
Two isolation variables are defined:

\begin{description}
\item {\textbf{Calorimeter isolation} ($\etcone$)}: Sum of transverse energies by the calibrated topo-clusters 
with  $\Delta R<0.2$ with respect to the lepton. An $\et,\eta$ dependent pileup correction is applied. For electron, the energy leakage due to the bremstralung is compensated. 

\item {\textbf{Track isolation} ($\ptcone$)}: Sum of transverse momentum of tracks within the angular distance of $R=\min(0.2, 10\gev/\pt)$ with respect to the lepton. The variable cone size is intended to loosen the isolation cut for high-$\pt$ leptons, based on the fact that most of fake leptons are below $20\gev$.
\end{description}

The isolation requirement is performed by applying a cut in a 2D-plane of $\etcone$ and $\ptcone$. 
In the analysis, the \textttb{GradientLoose} working point is chosen, in which a $\pt$-dependent cut is applied designed to recover the efficiency in high-$\pt$. Figure \ref{fig::objDef::isoEff}  shows the isolation efficiency respectively for electrons and muons. \\

%%%%%%%%%%
\begin{figure}[h]
  \centering
    \subfig{0.6}{figures/ObjectDef/electronIsoEffFixedCutLoose_pt_156.pdf}{}
    \subfig{0.6}{figures/ObjectDef/muonIsoEffGradLoose_166.pdf}{}
    \caption{ Measured and simulated efficiency of the isolation requirement in case of (a) electrons \cite{156_ElectronEffMeas_2015data} and (b) muons \cite{166_muonPerformance2015data}. The $Z\ra ee/\mu\mu$ events are used for both MC and data.
      The \textttb{FixedCutLoose} working point is shown for the electrons where $\etcone/\ET<0.2$ and $\ptcone/\ET<0.15$ is applied, while the case with \textttb{GradientLoose} is shown for muons.
      \label{fig::objDef::isoEff} }
\end{figure}
%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Missing Transverse Energy} \label{sec::objDef::met}
Missing Transverse Energy ($\met$) is an extremely important proxy to new physics 
since it is directly related with the activity of invisible particles. 
$\met$ is calculated by the transverse momentum imbalance of visible particles, using the reconstructed objects as well as isolated tracks that are not associated with any objects (``soft term'').
It is contructed by four independent terms as shown in Eq. (\ref{eq::metDef}):
\begin{align}
\bm{E_\mathrm{T}^{\mathrm{miss.}}} :=  - \sum \bmet^{e} - \sum \bmet^{\mu} - \sum \bmet^{\mathrm{jet}} - \bmet^{\mathrm{soft}}.
%\met_{x,y} :=  - \sum \ET^{e}_{x,y} - \sum \ET^{\mu}_{x,y} - \sum \ET^{\mathrm{jet}}_{x,y} - \sum \ET^{\mathrm{soft}}_{x,y}.
\label{eq::metDef}
\end{align}
where the first three terms (electron term / muon term / jet term) are the the vectoral sum of $\ET$ of the objects after the calibration and the overlap removal. 
\footnote{JVT selection for jets in addition to prevent the contribution from pile-up.}
%The overlap removal procedure used for $\met$ calculaltion slightly differs from the baseline method described in the previous sub-section in that
%
%Jets with $\pt>20\gev$ are included in the jet term in the MET calculation, otherwise subjected to the soft term with the track momenta.
%unique fraction
%
The last term is the soft term accounting for the residual visible momentum mainly from soft jets ($\pt<20\gev$) and mis-identified muons.
Is is calculated by the track soft term algorism (TST) \cite{175_MET_Run2_exp}, 
summing over the momenta of tracks that are not associated to any jets, and are isolated by $\Delta R>0.2$ from any reconstructed EM clusters. 
%The momenta of tracks found to associated with the reconstructed muons are replaced into that by the combined ID+MS muon tracks. 
Tracks with the momentum uncertainties larger than $40\%$, and the high-$\pt$ tracks ($\pt>200 \gev$ in $|\eta|<1.5$ or $\pt>150 \gev$ in $|\eta|>1.5$) with questionable quality of momemtum measurement satisfying following conditions are removed to prevent potential large error in the calculation:
\begin{align}
\ptcone/\pt>0.1, \,\,\, \mathrm{and} \,\,\, \frac{\etcone}{\pt+\ptcone}<0.6, \,\,\,  \mathrm{and} \,\,\, \frac{\ptcone}{\pt+\ptcone}<0.6.
\end{align}
% isolation variable defined in previous sub-section
One of the biggest advantages to calculating the soft term using tracks instead of clusters is the robustness against pile-up.
Figure \ref{fig::objDef::metPerformance} show the resolution of TST as function of pile-up,
where the bias due to pile-up is shown to be highly suppressed.

\fig[100]{ObjectDef/metReso_177.pdf}
{
Simulated and measured resolution of the TST as function of number of number of reconstructed primary vertices per event, using the $Z\ra ee$ events without jets with $\pt>20\gev$ \cite{177_MET_data2016}.
}
{fig::objDef::metPerformance}

%%%%%%%%%%
%\begin{figure}[h]
%  \centering
%    \subfig{0.48}{figures/ObjectDef/metTST.pdf}{}
%    \subfig{0.48}{figures/ObjectDef/met_Zmumu.pdf}{}
%    \caption{ (a) Pile-up dependency of resolution of the TST, 
%      and (b) simulated or measured using $Z\ra \ell\ell$ events in which the TST is nearly zero with an ideal measurement \cite{177_MET_data2016}. 
%      \label{fig::objDef::metPerformance}
% }
%\end{figure}
%%%%%%%%%%



%%%%%%%%%
\clearpage
\section{Object Definition in the Analysis} \label{sec::objDef::objDef}
The requirements for objects used in the analysis are summarized in Table \ref{tab::objDef::summary}.
For electrons and muons, two types of working point are defined;
``baseline'' is the loose selection criteria oriented to veto extra prompt leptons in the event; 
``signal'' is the tighter working point aiming to reject fake leptons where tighter identification, the impact parameter cut, and the isolation requirement are imposed in on top of the baseline requirement.
Signal regions are defined with exactly one baseline and signal lepton, given that the targeted signal events contain exactly one prompt lepton. 
%Jet used in the analysis is uniquely defined. JVT cut is required to avoid the impact by pile-up on the analysis. \\
%% OR通ってないjet使うこともできればいう


\begin{table}[hpt]
\caption{Summary of object definition used in the analysis. 
In addition to the listed criteria, objects are required to pass the reconstruction, identification and the overlap removal.
The $\pt$ requirements are based on the transverse momentum after the calibrations.
}
\centering
\begin{tabular}{l|l|l}
  \toprule
  \hline
  \textbf{Electrons}	& Baseline			& Signal \\
  \hline
  $p_{T}$		& $>7\gev$	                & $>7\gev$ \\
  Identification        & \textttb{Loose}  
        		& \textttb{Tight}  \\
  Isolation		& -				& \textttb{GradientLoose} \\
  Impact parameter cuts & -				& $z_0|\sin{\theta}| < 0.5 \mathrm{mm}$, $|d_0|/\sigma(d_0)<5$ \\

  \hline
  \textbf{Muons}	& Baseline			& Signal \\
  \hline
  $p_{T}$		& $>6\gev$	                & $>6\gev$ \\
  Identification	& \textttb{Medium}
                        & \textttb{Medium}   \\
  Isolation		& -				& \textttb{GradientLoose} \\
  Impact parameter cuts & -				& $z_0|\sin{\theta}| < 0.5\mathrm{mm}$, $|d_0|/\sigma(d_0)<3$ \\
  \hline
  \multicolumn{3}{l}{\textbf{Jets}} \\
  \hline
  Clustering Algorithm  & \multicolumn{2}{l}{anti-$k_{\mathrm{T}}$ ($r=0.4$)}  \\
  $p_{T}$		& \multicolumn{2}{l}{$>30\gev$}  \\
    JVT			& \multicolumn{2}{l}{$>0.57$ for $\pt<60 \gev$} 	 \\
  $b$-tag	        & \multicolumn{2}{l}{MV2c10 algorithm, 77\% efficiency working point} \\
  \hline
\end{tabular}
\label{tab::objDef::summary}
\end{table}

